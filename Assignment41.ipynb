{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9421ba18-92cd-4203-bd2c-2a689bbcefb6",
   "metadata": {},
   "source": [
    "## Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf586d3a-aaf1-4d5c-8bdf-b98e6dc04b0e",
   "metadata": {},
   "source": [
    "### Min-max normalization (usually called feature scaling) performs a linear transformation on the original data. This technique gets all the scaled data in the range (0, 1). The formula to achieve this is the following:\n",
    "### X_scaled=(X-X_min)/(X_max-X_min)\n",
    "### Min-max normalization preserves the relationships among the original data values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64f42193-ae17-46a5-8d50-4d36079d10c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e922c433-62b5-4bb3-9683-8dca987008eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=sns.load_dataset('taxis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0d2ec14-f453-4b01-8447-deb8c5fd399b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.043597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.037330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.209809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.058856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6428</th>\n",
       "      <td>0.020436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6429</th>\n",
       "      <td>0.510627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6430</th>\n",
       "      <td>0.112807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6431</th>\n",
       "      <td>0.030518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6432</th>\n",
       "      <td>0.104905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6433 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0     0.043597\n",
       "1     0.021526\n",
       "2     0.037330\n",
       "3     0.209809\n",
       "4     0.058856\n",
       "...        ...\n",
       "6428  0.020436\n",
       "6429  0.510627\n",
       "6430  0.112807\n",
       "6431  0.030518\n",
       "6432  0.104905\n",
       "\n",
       "[6433 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "min_max=MinMaxScaler()\n",
    "pd.DataFrame(min_max.fit_transform(df[['distance']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1003c346-6ae4-45f1-9f29-915d8445e6be",
   "metadata": {},
   "source": [
    "## Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling? Provide an example to illustrate its application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c64ab8-5ad2-41c5-a8cc-eaf35e66634e",
   "metadata": {},
   "source": [
    "### Unit vector technique means dividing each component by the magnitude of  length of the vector ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9286e1d4-fe06-43f5-a077-7f9f4126b407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e39a123-218f-4c25-899c-f025e296afef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.955927</td>\n",
       "      <td>0.293606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.953890</td>\n",
       "      <td>0.300157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.975026</td>\n",
       "      <td>0.222089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.992614</td>\n",
       "      <td>0.121319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6428</th>\n",
       "      <td>0.973360</td>\n",
       "      <td>0.229280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6429</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6430</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6431</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6432</th>\n",
       "      <td>0.975818</td>\n",
       "      <td>0.218583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6433 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1\n",
       "0     0.955927  0.293606\n",
       "1     1.000000  0.000000\n",
       "2     0.953890  0.300157\n",
       "3     0.975026  0.222089\n",
       "4     0.992614  0.121319\n",
       "...        ...       ...\n",
       "6428  0.973360  0.229280\n",
       "6429  1.000000  0.000000\n",
       "6430  1.000000  0.000000\n",
       "6431  1.000000  0.000000\n",
       "6432  0.975818  0.218583\n",
       "\n",
       "[6433 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(normalize(df[['fare','tip']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1370ca7d-5a03-421b-9e47-dab5302d4eac",
   "metadata": {},
   "source": [
    "## Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an example to illustrate its application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8439f5e-1b72-41a7-8aab-04d259aaa1d8",
   "metadata": {},
   "source": [
    "### Principal component analysis, or PCA, is a dimensionality reduction method that is often used to reduce the dimensionality of large data sets, by transforming a large set of variables into a smaller one that still contains most of the information in the large set.\n",
    "### Reducing the number of variables of a data set naturally comes at the expense of accuracy, but the trick in dimensionality reduction is to trade a little accuracy for simplicity. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0b3f61-5ebb-4872-8522-5b8a3a393c65",
   "metadata": {},
   "source": [
    "## Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature Extraction? Provide an example to illustrate this concept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52f341d-133f-4e63-9dbd-a1a8efc3eaf2",
   "metadata": {},
   "source": [
    "### PCA can be used to identify the most important features in a dataset, which can be used to build predictive models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fae4af-18be-41e1-97f5-99e8a25fb605",
   "metadata": {},
   "source": [
    "## Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to preprocess the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99d41eb-1fed-45dd-af85-fdd1d8c8b378",
   "metadata": {},
   "source": [
    "### In preprocessing of data we use Min-Max scaling to normalize the widely distributed data in price, rating and delivery time to convert these in 0 to 1 range, which will help us easily to compare the features maintaining the importance of each feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe3f370-9e05-483d-aa88-a0c3aa3ab4d0",
   "metadata": {},
   "source": [
    "## Q6. You are working on a project to build a model to predict stock prices. The dataset contains many features, such as company financial data and market trends. Explain how you would use PCA to reduce the dimensionality of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c404692-ef3c-4ed9-b081-8ec98edfce80",
   "metadata": {},
   "source": [
    "### With the help of PCA, we will define a new feature which explain the variance of both the old features. Now the dimensionality of Dataset is reduced to 1, which is easy to study."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa712977-ad72-45f5-8eaf-f04681aae7fd",
   "metadata": {},
   "source": [
    "## Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the values to a range of -1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2a6698b-4001-498a-adac-0bc39133d699",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[1,5,10,15,20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e6924d0-2dea-4714-9716-57f28ee01b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc1d8fc7-60fa-4477-a50e-93874ffdcd63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4505a9ce-1bd4-4bc8-967a-a165e1dfd617",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst1=[]\n",
    "for i in lst:\n",
    "    min_max=(i-min(lst))/(max(lst)-min(lst))\n",
    "    lst1.append(min_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91206312-b3cc-49ac-90c0-41887d28425d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.21052631578947367, 0.47368421052631576, 0.7368421052631579, 1.0]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa4634d-fab3-4206-8ecb-a9d9839638b4",
   "metadata": {},
   "source": [
    "## Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform Feature Extraction using PCA. How many principal components would you choose to retain, and why? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2868cf1-6207-4e07-b957-a95a6bbee751",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
